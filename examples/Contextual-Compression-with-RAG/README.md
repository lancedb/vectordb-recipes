# ğŸ”Search engine using SAM & CLIP

<a href="https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/Contextual-Compression-with-RAG/main.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a>  
[![Medium](https://img.shields.io/badge/Medium-12100E?style=for-the-badge&logo=medium&logoColor=white)](https://medium.com/etoai/enhance-rag-integrate-contextual-compression-and-filtering-for-precision-a29d4a810301)


###  ğŸ« Enhance RAG: Integrate Contextual Compression and Filtering for Precision.
Follow the Colab Notebook for full code.

## Interface ğŸŒŸ

1. Load the Model from Huggingface.
2. Instantiate Contextual Compressor from Langchain.
3. Create a pipeline with different retrieving filters.
4. Get the answer using QA chain.