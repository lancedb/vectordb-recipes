{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c11fde21",
   "metadata": {
    "id": "c11fde21"
   },
   "source": [
    "# Multimodal search using CLIP\n",
    "\n",
    "![mmclip](https://www.researchgate.net/publication/363808556/figure/fig2/AS:11431281086053770@1664048343869/Architectures-of-the-designed-machine-learning-approaches-with-OpenAI-CLIP-model.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c53ccb-5654-4150-93a2-cdf9ff4d8d26",
   "metadata": {
    "id": "06c53ccb-5654-4150-93a2-cdf9ff4d8d26"
   },
   "source": [
    "### Installing all dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69fb1627",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "69fb1627",
    "outputId": "c72abc4e-a28e-43e2-b91a-420bd9de938c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.2/298.2 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
      "Requirement already satisfied: install in /usr/local/lib/python3.10/dist-packages (1.3.5)\n",
      "Requirement already satisfied: tantivy==0.20.1 in /usr/local/lib/python3.10/dist-packages (0.20.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet -U lancedb\n",
    "!pip install --quiet gradio==3.41.2  transformers torch torchvision duckdb\n",
    "!pip install pip install pip install tantivy==0.20.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d53ade3",
   "metadata": {
    "id": "2d53ade3"
   },
   "source": [
    "## First run setup: Download data and pre-process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b7e97f9",
   "metadata": {
    "id": "9b7e97f9"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import PIL\n",
    "import duckdb\n",
    "import lancedb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ba75742",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ba75742",
    "outputId": "02d0c53b-bb80-4fe5-9f58-df01ae42a2f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-01-23 17:06:32--  https://eto-public.s3.us-west-2.amazonaws.com/datasets/diffusiondb_lance.tar.gz\n",
      "Resolving eto-public.s3.us-west-2.amazonaws.com (eto-public.s3.us-west-2.amazonaws.com)... 52.218.181.9, 52.218.213.137, 52.218.176.9, ...\n",
      "Connecting to eto-public.s3.us-west-2.amazonaws.com (eto-public.s3.us-west-2.amazonaws.com)|52.218.181.9|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6121107645 (5.7G) [application/x-gzip]\n",
      "Saving to: ‘diffusiondb_lance.tar.gz’\n",
      "\n",
      "diffusiondb_lance.t 100%[===================>]   5.70G  62.1MB/s    in 2m 5s   \n",
      "\n",
      "2024-01-23 17:08:37 (46.7 MB/s) - ‘diffusiondb_lance.tar.gz’ saved [6121107645/6121107645]\n",
      "\n",
      "diffusiondb_test/\n",
      "diffusiondb_test/_versions/\n",
      "diffusiondb_test/_latest.manifest\n",
      "diffusiondb_test/data/\n",
      "diffusiondb_test/data/138fc0d8-a806-4b10-84f8-00dc381afdad.lance\n",
      "diffusiondb_test/_versions/1.manifest\n"
     ]
    }
   ],
   "source": [
    "!wget https://eto-public.s3.us-west-2.amazonaws.com/datasets/diffusiondb_lance.tar.gz\n",
    "!tar -xvf diffusiondb_lance.tar.gz\n",
    "!mv diffusiondb_test rawdata.lance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fcbf61",
   "metadata": {
    "id": "e2fcbf61"
   },
   "source": [
    "## Create / Open LanceDB Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3317a3c",
   "metadata": {
    "id": "b3317a3c"
   },
   "outputs": [],
   "source": [
    "import pyarrow.compute as pc\n",
    "import lance\n",
    "\n",
    "db = lancedb.connect(\"~/datasets/demo\")\n",
    "if \"diffusiondb\" in db.table_names():\n",
    "    tbl = db.open_table(\"diffusiondb\")\n",
    "else:\n",
    "    # First data processing and full-text-search index\n",
    "    data = lance.dataset(\"rawdata.lance\").to_table()\n",
    "    # remove null prompts\n",
    "    # tbl = db.create_table(\"diffusiondb\", data.filter(~pc.field(\"prompt\").is_null()), mode=\"overwrite\") # OOM\n",
    "    tbl = db.create_table(\"diffusiondb\", data, mode=\"overwrite\")\n",
    "    tbl.create_fts_index([\"prompt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e4fc03",
   "metadata": {
    "id": "d7e4fc03"
   },
   "source": [
    "## Create CLIP embedding function for the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8331d87",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f8331d87",
    "outputId": "54d77a42-340d-42f4-e890-38512af7525f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import CLIPModel, CLIPProcessor, CLIPTokenizerFast\n",
    "\n",
    "MODEL_ID = \"openai/clip-vit-base-patch32\"\n",
    "\n",
    "tokenizer = CLIPTokenizerFast.from_pretrained(MODEL_ID)\n",
    "model = CLIPModel.from_pretrained(MODEL_ID)\n",
    "processor = CLIPProcessor.from_pretrained(MODEL_ID)\n",
    "\n",
    "\n",
    "def embed_func(query):\n",
    "    inputs = tokenizer([query], padding=True, return_tensors=\"pt\")\n",
    "    text_features = model.get_text_features(**inputs)\n",
    "    return text_features.detach().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82c50eaf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "82c50eaf",
    "outputId": "bbae933a-9652-48ec-f7f9-c479f7a24118"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prompt: string\n",
       "seed: uint32\n",
       "step: uint16\n",
       "cfg: float\n",
       "sampler: string\n",
       "width: uint16\n",
       "height: uint16\n",
       "timestamp: timestamp[s]\n",
       "image_nsfw: float\n",
       "prompt_nsfw: float\n",
       "vector: fixed_size_list<item: float>[512]\n",
       "  child 0, item: float\n",
       "image: binary"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl.schema\n",
    "# tbl.to_pandas().head() # OOM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4d7a54",
   "metadata": {
    "id": "5e4d7a54"
   },
   "source": [
    "\n",
    "## Search functions for Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10b8de6d",
   "metadata": {
    "id": "10b8de6d"
   },
   "outputs": [],
   "source": [
    "def find_image_vectors(query):\n",
    "    emb = embed_func(query)\n",
    "    code = (\n",
    "        \"import lancedb\\n\"\n",
    "        \"db = lancedb.connect('~/datasets/demo')\\n\"\n",
    "        \"tbl = db.open_table('diffusiondb')\\n\\n\"\n",
    "        f\"embedding = embed_func('{query}')\\n\"\n",
    "        \"tbl.search(embedding).limit(9).to_df()\"\n",
    "    )\n",
    "    return (_extract(tbl.search(emb).limit(9).to_pandas()), code)\n",
    "\n",
    "\n",
    "def find_image_keywords(query):\n",
    "    code = (\n",
    "        \"import lancedb\\n\"\n",
    "        \"db = lancedb.connect('~/datasets/demo')\\n\"\n",
    "        \"tbl = db.open_table('diffusiondb')\\n\\n\"\n",
    "        f\"tbl.search('{query}').limit(9).to_df()\"\n",
    "    )\n",
    "    return (_extract(tbl.search(query).limit(9).to_pandas()), code)\n",
    "\n",
    "\n",
    "def find_image_sql(query):\n",
    "    code = (\n",
    "        \"import lancedb\\n\"\n",
    "        \"import duckdb\\n\"\n",
    "        \"db = lancedb.connect('~/datasets/demo')\\n\"\n",
    "        \"tbl = db.open_table('diffusiondb')\\n\\n\"\n",
    "        \"diffusiondb = tbl.to_lance()\\n\"\n",
    "        f\"duckdb.sql('{query}').to_df()\"\n",
    "    )\n",
    "    diffusiondb = tbl.to_lance()\n",
    "    return (_extract(duckdb.sql(query).to_df()), code)\n",
    "\n",
    "\n",
    "def _extract(df):\n",
    "    image_col = \"image\"\n",
    "    return [\n",
    "        (PIL.Image.open(io.BytesIO(row[image_col])), row[\"prompt\"])\n",
    "        for _, row in df.iterrows()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7Q28Ro20Wxa9",
   "metadata": {
    "id": "7Q28Ro20Wxa9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61aaf19b",
   "metadata": {
    "id": "61aaf19b"
   },
   "source": [
    "## Setup Gradio interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6f40300",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 671
    },
    "id": "b6f40300",
    "outputId": "f10797e0-2de3-44bd-91c9-b1ddf697f6e4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-61a30d121fae>:18: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "  gallery = gr.Gallery(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "application/javascript": "(async (port, path, width, height, cache, element) => {\n                        if (!google.colab.kernel.accessAllowed && !cache) {\n                            return;\n                        }\n                        element.appendChild(document.createTextNode(''));\n                        const url = await google.colab.kernel.proxyPort(port, {cache});\n\n                        const external_link = document.createElement('div');\n                        external_link.innerHTML = `\n                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n                                    https://localhost:${port}${path}\n                                </a>\n                            </div>\n                        `;\n                        element.appendChild(external_link);\n\n                        const iframe = document.createElement('iframe');\n                        iframe.src = new URL(path, url).toString();\n                        iframe.height = height;\n                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n                        iframe.width = width;\n                        iframe.style.border = 0;\n                        element.appendChild(iframe);\n                    })(7861, \"/\", \"100%\", 500, false, window.element)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        with gr.Tab(\"Embeddings\"):\n",
    "            vector_query = gr.Textbox(value=\"portraits of a person\", show_label=False)\n",
    "            b1 = gr.Button(\"Submit\")\n",
    "        with gr.Tab(\"Keywords\"):\n",
    "            keyword_query = gr.Textbox(value=\"ninja turtle\", show_label=False)\n",
    "            b2 = gr.Button(\"Submit\")\n",
    "        with gr.Tab(\"SQL\"):\n",
    "            sql_query = gr.Textbox(\n",
    "                value=\"SELECT * from diffusiondb WHERE image_nsfw >= 2 LIMIT 9\",\n",
    "                show_label=False,\n",
    "            )\n",
    "            b3 = gr.Button(\"Submit\")\n",
    "    with gr.Row():\n",
    "        code = gr.Code(label=\"Code\", language=\"python\")\n",
    "    with gr.Row():\n",
    "        gallery = gr.Gallery(\n",
    "            label=\"Found images\", show_label=False, elem_id=\"gallery\"\n",
    "        ).style(columns=[3], rows=[3], object_fit=\"contain\", height=\"auto\")\n",
    "\n",
    "    b1.click(find_image_vectors, inputs=vector_query, outputs=[gallery, code])\n",
    "    b2.click(find_image_keywords, inputs=keyword_query, outputs=[gallery, code])\n",
    "    b3.click(find_image_sql, inputs=sql_query, outputs=[gallery, code])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pEdiGi9EW0ZO",
   "metadata": {
    "id": "pEdiGi9EW0ZO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "511a7c77cb034b09af5465c01316a0f4bb20176d139e60e6d7915f9a637a5037"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
